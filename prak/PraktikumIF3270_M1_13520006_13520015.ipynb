{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediksi Hujan di Denpasar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praktikum ini menggunakan _dataset_ [Denpasar Weather Data](https://www.kaggle.com/datasets/cornflake15/denpasarbalihistoricalweatherdata?select=openweatherdata-denpasar-1990-2020v0.1.csv) dengan modifikasi. _Dataset_ digunakan untuk melakukan prediksi penarikan kesimpulan kebenaran kondisi hujan pada kondisi tertentu. Hal itu diperoleh dengan meninjau `raining` (diekstrak dari `weather_main`) sebagai target. Fitur yang digunakan adalah sebagai berikut:\n",
    "- `hour` (diekstrak dari `dt_iso`)\n",
    "- `temp`\n",
    "- `temp_min`\n",
    "- `temp_max`\n",
    "- `pressure`\n",
    "- `humidity`\n",
    "- `wind_speed`\n",
    "- `wind_deg`\n",
    "\n",
    "Tujuan praktikum:\n",
    "1.   Peserta memahami rangkaian proses analitik data menggunakan pendekatan pembelajaran mesin. \n",
    "2.   Peserta memahami bahwa proses pengembangan model pembelajaran mesin juga ditentukan dari kualitas data, penanganan data, dan penentuan algoritma serta hiperparameternya; tidak cukup hanya dengan memastikan implementasi algoritma berjalan tanpa kesalahan.\n",
    "3.   Peserta mampu menginterpretasikan hasil dari evaluasi model dalam proses analitik menggunakan pendekatan pembelajaran mesin.\n",
    "\n",
    "Praktikum dilaksanakan secara berkelompok. Setiap kelompok terdiri atas 2 mahasiswa. Perhatikan bahwa terdapat berkas yang harus dikumpulkan sebelum waktu praktikum selesai (17 April 2023, pukul 10.59 WIB) dan berkas yang dikumpulkan setelah waktu praktikum selesai (17 April 2023, pukul 23.59 WIB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persiapan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>raining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25.82</td>\n",
       "      <td>25.82</td>\n",
       "      <td>25.82</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1.36</td>\n",
       "      <td>225</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26.20</td>\n",
       "      <td>26.20</td>\n",
       "      <td>26.20</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2.09</td>\n",
       "      <td>247</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26.45</td>\n",
       "      <td>26.45</td>\n",
       "      <td>26.45</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2.44</td>\n",
       "      <td>262</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>26.80</td>\n",
       "      <td>26.80</td>\n",
       "      <td>26.80</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2.29</td>\n",
       "      <td>271</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>27.04</td>\n",
       "      <td>27.04</td>\n",
       "      <td>27.04</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>82</td>\n",
       "      <td>1.71</td>\n",
       "      <td>274</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264919</th>\n",
       "      <td>19</td>\n",
       "      <td>27.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>94</td>\n",
       "      <td>4.10</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264920</th>\n",
       "      <td>20</td>\n",
       "      <td>27.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>94</td>\n",
       "      <td>5.70</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264921</th>\n",
       "      <td>21</td>\n",
       "      <td>28.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>83</td>\n",
       "      <td>6.70</td>\n",
       "      <td>290</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264922</th>\n",
       "      <td>22</td>\n",
       "      <td>28.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>83</td>\n",
       "      <td>6.20</td>\n",
       "      <td>290</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264923</th>\n",
       "      <td>23</td>\n",
       "      <td>28.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>83</td>\n",
       "      <td>5.70</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264924 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hour   temp  temp_min  temp_max  pressure  humidity  wind_speed  \\\n",
       "0          0  25.82     25.82     25.82    1010.0        86        1.36   \n",
       "1          1  26.20     26.20     26.20    1011.0        84        2.09   \n",
       "2          2  26.45     26.45     26.45    1011.0        84        2.44   \n",
       "3          3  26.80     26.80     26.80    1011.0        82        2.29   \n",
       "4          4  27.04     27.04     27.04    1010.0        82        1.71   \n",
       "...      ...    ...       ...       ...       ...       ...         ...   \n",
       "264919    19  27.00     27.00     27.00    1007.0        94        4.10   \n",
       "264920    20  27.00     27.00     27.00    1007.0        94        5.70   \n",
       "264921    21  28.00     28.00     28.00    1007.0        83        6.70   \n",
       "264922    22  28.00     28.00     28.00    1007.0        83        6.20   \n",
       "264923    23  28.00     28.00     28.00    1008.0        83        5.70   \n",
       "\n",
       "        wind_deg  raining  \n",
       "0            225     True  \n",
       "1            247     True  \n",
       "2            262     True  \n",
       "3            271     True  \n",
       "4            274    False  \n",
       "...          ...      ...  \n",
       "264919       300    False  \n",
       "264920       300    False  \n",
       "264921       290    False  \n",
       "264922       290    False  \n",
       "264923       300    False  \n",
       "\n",
       "[264924 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"openweatherdata-denpasar-1990-2020v0.1-simplified.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=\"raining\")\n",
    "y = data[\"raining\"].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=123)\n",
    "\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_val = pd.concat([X_val, y_val], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disediakan data yang sudah dibagi menjadi data latih (`df_train`), data validasi (`df_val`), dan data uji (`df_test`).\n",
    "\n",
    "**Bagian 1**: (batas waktu: 17 April 2023, 10.59 WIB)\n",
    "\n",
    "1. Buatlah _baseline_ dengan menggunakan model _logistic regression_.\n",
    "2. Lakukan analisis data terkait hal berikut:\n",
    "    - _duplicate value_,\n",
    "    - _missing value_,\n",
    "    - _outlier_,\n",
    "    - _balance of data_.\n",
    "3. Jelaskan rencana penanganan yang ada pada poin 2.\n",
    "4. Jelaskan teknik _encoding_ yang digunakan terhadap data yang disediakan, disertai dengan alasan.\n",
    "5. Buatlah desain eksperimen dengan menentukan hal berikut:\n",
    "    - tujuan eksperimen,\n",
    "    - variabel dependen dan independen,\n",
    "    - strategi eksperimen,\n",
    "    - skema validasi.\n",
    "    \n",
    "**Bagian 2**: (batas waktu: 17 April 2023, 23.59 WIB)\n",
    "\n",
    "6. Implementasikan strategi eksperimen dan skema validasi yang telah ditentukan pada poin 5.\n",
    "7. Berdasarkan hasil prediksi yang dihasilkan, buatlah kesimpulan analisis karakteristik kondisi hujan.\n",
    "\n",
    "---\n",
    "\n",
    "Jika terdapat perubahan jawaban pada poin 1—5 (contoh: perbedaan penanganan _outlier_), jelaskan pada laporan mengenai jawaban sebelum, jawaban sesudah, dan alasan pengubahan jawaban."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada sel ini, jelaskan pembagian tugas/kerja per anggota kelompok dalam eksperimen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Deliverable_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Deliverable_ yang akan dihasilkan adalah sebagai berikut:\n",
    "1. berkas _notebook_ dengan format nama `PraktikumIF3270_M1_NIM1_NIM2.ipynb` untuk Bagian 1;\n",
    "2. berkas _notebook_ dengan format nama `PraktikumIF3270_M2_NIM1_NIM2.ipynb` untuk Bagian 1 + Bagian 2; serta\n",
    "3. berkas laporan dengan format nama `PraktikumIF3270_NIM1_NIM2.pdf` yang mencakup hal berikut:\n",
    "    - hasil analisis data,\n",
    "    - penanganan dari hasil analisis data,\n",
    "    - justifikasi teknik-teknik yang dipilih,\n",
    "    - perubahan yang dilakukan pada jawaban poin 1—5 jika ada,\n",
    "    - desain eksperimen,\n",
    "    - hasil eksperimen.\n",
    "    - analisis dari hasil eksperimen,\n",
    "    - kesimpulan,\n",
    "    - pembagian tugas/kerja per anggota kelompok\n",
    "\n",
    "Batas waktu pengumpulan:\n",
    "- _Deliverable_ poin 1: Senin, 17 April 2023, pukul 10.59 WIB\n",
    "- _Deliverable_ poin 2: Senin, 17 April 2023, pukul 23.59 WIB\n",
    "- _Deliverable_ poin 3: Senin, 17 April 2023, pukul 23.59 WIB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8736198924223837\n",
      "Test Accuracy: 0.8728508068321224\n",
      "Precision: 0.5824675324675325\n",
      "Recall: 0.12830782434558718\n",
      "F1: 0.21029187668503105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[45351,   643],\n",
       "       [ 6094,   897]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "accuracy = model.score(X_val, y_val)\n",
    "print('Validation Accuracy:', accuracy)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using accuracy score\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision:', precision)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall:', recall)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1:', f1)\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banyak data duplicate:  7253\n",
      "banyak data missing: \n",
      " hour          0\n",
      "temp          0\n",
      "temp_min      0\n",
      "temp_max      0\n",
      "pressure      0\n",
      "humidity      0\n",
      "wind_speed    0\n",
      "wind_deg      0\n",
      "raining       0\n",
      "dtype: int64\n",
      "banyak outliers:\n",
      "hour             0\n",
      "temp          1458\n",
      "temp_min      1716\n",
      "temp_max       547\n",
      "pressure      1067\n",
      "humidity       231\n",
      "wind_speed    3439\n",
      "wind_deg         0\n",
      "dtype: int64\n",
      "banyak data raining:  34901\n",
      "banyak data not raining:  230023\n"
     ]
    }
   ],
   "source": [
    "#2. Lakukan analisis data terkait hal berikut\n",
    "#duplicate value\n",
    "print(\"banyak data duplicate: \", data.duplicated().sum())\n",
    "\n",
    "#missing value\n",
    "print(\"banyak data missing: \\n\",data.isnull().sum())\n",
    "\n",
    "#outliers\n",
    "y = data[\"raining\"]\n",
    "X = data.drop(columns=\"raining\")\n",
    "LowOutliner = 0\n",
    "HighOutliner = 0\n",
    "\n",
    "Q1 = X.quantile(0.25)\n",
    "Q3 = X.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = (X< (Q1 - 1.5 * IQR)) | (X > (Q3 + 1.5 * IQR))\n",
    "print(\"banyak outliers:\")\n",
    "print(outliers.sum())\n",
    "\n",
    "#handle balance of data\n",
    "print(\"banyak data raining: \", y.value_counts()[1])\n",
    "print(\"banyak data not raining: \", y.value_counts()[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Jelaskan rencana penanganan yang ada pada poin 2.\n",
    "    - Data yang duplicate rencananya akan dihapuskan\n",
    "    - Data yang missing rencananya akan digantikan dengan median\n",
    "    - Data outliers akan digantikan dengan median\n",
    "    - Akan dilakukan oversampling dan undersampling untuk menghandle balance of data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Jelaskan teknik encoding yang digunakan terhadap data yang disediakan, disertai dengan alasan.\n",
    "    - Pada data Denpasar Weather Data, hanya terdapat satu kolom non numeric, yaitu kolom raining. Kolom raining nantinya akan di encoding dengan menggunakan label encoding. Teknik encoding ini dipilih karena raining merupakan kolom target, sehingga tidak perlu men-generate kolom baru (bila melakukan one hot encoding). Selain itu, label encoding cukup mudah dan cepat dilakukan, serta tidak membutuhkan banyak memori dan waktu komputasi."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 Tujuan Eksperimen\n",
    "\n",
    "Tujuan dari eksperimen ini adalah untuk mencoba melakukan improvement terhadap baseline model yang sudah dibuat agar dapat lebih robust dalam melakukan prediksi data tidak terlihat.\n",
    "\n",
    "5.2 Variabel Dependen dan Independen\n",
    "\n",
    "Variabel dependen adalah fitur/kolom yang ingin diprediksi. \n",
    "Variabel independen adalah fitur/kolom yang digunakan untuk melakukan prediksi variabel dependen.\n",
    "\n",
    "Untuk dataset ini, Variabel dependen merupakan kolom **raining** dan Variable independen adalah kolom hour, temp, temp_min, temp_max, pressure, humidity, wind_speed, wind_deg.\n",
    "\n",
    "5.3 Strategi Eksperimen\n",
    "\n",
    "Data prepocessing: Melakukan cleaning dan modifikasi data seperti handling missing values, duplicate data, outliers, imbalanced data.\n",
    "\n",
    "Feature selection: Tidak diperlukan karena semua data sudah cukup relevan.\n",
    "\n",
    "Hyperparameter tuning: Melakukan tuning parameter dengan menggunakan teknik grid search\n",
    "\n",
    "5.4 Skema Validasi\n",
    "\n",
    "Validasi menggunakan k-fold *cross-validation* menggunakan data training yang sudah dipisah sebelumnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banyak data duplicate:  3309\n",
      "banyak data missing: \n",
      " hour          0\n",
      "temp          0\n",
      "temp_min      0\n",
      "temp_max      0\n",
      "pressure      0\n",
      "humidity      0\n",
      "wind_speed    0\n",
      "wind_deg      0\n",
      "raining       0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6 Implementasi Strategi Eksperimen\n",
    "\n",
    "# handle duplicate values\n",
    "print(\"banyak data duplicate: \", df_train.duplicated().sum())\n",
    "df_train = df_train.drop_duplicates(keep='first')\n",
    "df_val = df_val.drop_duplicates(keep='first')\n",
    "df_test = df_test.drop_duplicates(keep='first')\n",
    "\n",
    "#     - _missing value_,\n",
    "print(\"banyak data missing: \\n\",df_train.isnull().sum())\n",
    "# tidak ada missing value\n",
    "print()\n",
    "\n",
    "#handle outliers\n",
    "y_train = df_train[\"raining\"]\n",
    "X_train = df_train.drop(columns=\"raining\")\n",
    "y_val = df_val[\"raining\"]\n",
    "X_val = df_val.drop(columns=\"raining\")\n",
    "y_test = df_test[\"raining\"]\n",
    "X_test = df_test.drop(columns=\"raining\")\n",
    "\n",
    "LowOutliner = 0\n",
    "HighOutliner = 0\n",
    "\n",
    "for i in X_train.columns:\n",
    "    Q1 = X[i].quantile(0.25)\n",
    "    Q2 = X[i].quantile(0.5)\n",
    "    Q3 = X[i].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    MIN = Q1 - 1.5 * IQR\n",
    "    MAX = Q3 + 1.5 * IQR\n",
    "    outliers = df_train[(X_train[i] < MIN) | (X_train[i] > MAX)]\n",
    "    df_train.loc[outliers.index, i] = Q2\n",
    "\n",
    "for i in X_val.columns:\n",
    "    Q1 = X[i].quantile(0.25)\n",
    "    Q2 = X[i].quantile(0.5)\n",
    "    Q3 = X[i].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    MIN = Q1 - 1.5 * IQR\n",
    "    MAX = Q3 + 1.5 * IQR\n",
    "    outliers = df_val[(X_val[i] < MIN) | (X_val[i] > MAX)]\n",
    "    df_val.loc[outliers.index, i] = Q2\n",
    "\n",
    "for i in X_test.columns:\n",
    "    Q1 = X[i].quantile(0.25)\n",
    "    Q2 = X[i].quantile(0.5)\n",
    "    Q3 = X[i].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    MIN = Q1 - 1.5 * IQR\n",
    "    MAX = Q3 + 1.5 * IQR\n",
    "    outliers = df_test[(X_test[i] < MIN) | (X_test[i] > MAX)]\n",
    "    df_test.loc[outliers.index, i] = Q2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semua kolom fitur yang terdapat pada dataset Denpasar Feature Data diperlukan dan sudah cukup untuk memprediksi kolom target. Oleh karena itu, tidak ada kolom yang di drop dan ditambahkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversampling \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy=\"minority\",random_state=0)\n",
    "\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "model.fit(X_over, y_over)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7151877068198242\n",
      "Precision: 0.28456600312887737\n",
      "Recall: 0.7547574760337673\n",
      "F1: 0.413304082112356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32331, 13262],\n",
       "       [ 1714,  5275]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision:', precision)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall:', recall)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1:', f1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy=\"majority\",random_state=0)\n",
    "\n",
    "X_over, y_over = undersample.fit_resample(X_train, y_train)\n",
    "\n",
    "model.fit(X_over, y_over)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7164809250313796\n",
      "Precision: 0.28519503065154883\n",
      "Recall: 0.752182000286164\n",
      "F1: 0.4135787900243883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32417, 13176],\n",
       "       [ 1732,  5257]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision:', precision)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall:', recall)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1:', f1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Furniture\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 70.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Furniture\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Furniture\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Furniture\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Furniture\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.72656787        nan 0.72652966        nan 0.72649493\n",
      "        nan 0.72649493        nan 0.72659219        nan 0.72650187\n",
      "        nan 0.72658872]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 10, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning and skema validasi\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_over, y_over)\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid=params, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_over, y_over)\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8718763074816477\n",
      "Precision: 0.581924577373212\n",
      "Recall: 0.128058377450279\n",
      "F1: 0.20992142605840272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[44950,   643],\n",
       "       [ 6094,   895]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision:', precision)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall:', recall)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1:', f1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Analisis Hasil Eksperimen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
